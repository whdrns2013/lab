{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDS connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#             안내사항            #\n",
    "#################################\n",
    "\n",
    "# 1. pymysql을 이용하는 방법입니다.\n",
    "# 2. 필요한 모든 세팅을 아래 코드에 했으므로 바로 이용하시면 됩니다.\n",
    "# 3. 문제가 발생할 경우 박종혁에게 연락 부탁드립니다.\n",
    "\n",
    "\n",
    "#################################\n",
    "#             주의사항            #\n",
    "#################################\n",
    "\n",
    "# 1. 작업이 끝나면 반드시 연결을 닫아주세요. (conn.close())\n",
    "# 2. 한글 입력이 가능하도록 설정을 변경했습니다. (RDS - 파라미터그룹 - utf8mb4)\n",
    "# 3. 새로 생성되는 테이블의 CHAR SET 은 UTF-8로 설정해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import os\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = os.getcwd()\n",
    "path = '/yolov5/'\n",
    "env_file = [x for x in os.listdir(cur_path + path) if x.endswith(\".env\")]\n",
    "dotenv.load_dotenv(cur_path + path + env_file[0])\n",
    "\n",
    "# 연결 RDS 정보\n",
    "\n",
    "rds_host = os.environ[\"RDS_HOST\"]\n",
    "rds_port = int(os.environ[\"RDS_PORT\"])\n",
    "rds_database = os.environ[\"RDS_DATABASE\"]\n",
    "rds_username = os.environ[\"RDS_USERNAME\"]\n",
    "rds_password = os.environ[\"RDS_PASSWORD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymysql을 통한 로컬 - AWS RDS 연결\n",
    "\n",
    "conn = pymysql.connect(host = rds_host, user = rds_username, port = rds_port, database = rds_database, password = rds_password)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('event_name', 'varchar(40)', 'YES', '', None, '')\n",
      "('detecte_date', 'varchar(20)', 'YES', '', None, '')\n",
      "('detect_time', 'varchar(20)', 'YES', '', None, '')\n",
      "('object1_name', 'varchar(10)', 'YES', '', None, '')\n",
      "('object1_num', 'varchar(10)', 'YES', '', None, '')\n",
      "('object2_name', 'varchar(10)', 'YES', '', None, '')\n",
      "('object2_num', 'varchar(10)', 'YES', '', None, '')\n",
      "('object3_name', 'varchar(10)', 'YES', '', None, '')\n",
      "('object3_num', 'varchar(10)', 'YES', '', None, '')\n"
     ]
    }
   ],
   "source": [
    "# 명령문 실행\n",
    "\n",
    "## 명령문 작성\n",
    "sql = '''\n",
    "DESC test;\n",
    "'''\n",
    "\n",
    "## 명령문 실행\n",
    "cursor.execute(sql)\n",
    "\n",
    "## 실행 결과 출력\n",
    "response = cursor.fetchall()\n",
    "for data in response:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명령문 실행\n",
    "\n",
    "## 명령문 작성\n",
    "sql = '''\n",
    "select distinct event_name, detecte_date from test;\n",
    "'''\n",
    "\n",
    "## 명령문 실행\n",
    "cursor.execute(sql)\n",
    "\n",
    "## 실행 결과 출력\n",
    "response = cursor.fetchall()\n",
    "for data in response:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명령문 실행\n",
    "\n",
    "## 명령문 작성\n",
    "sql = '''\n",
    "delete from test;\n",
    "'''\n",
    "\n",
    "## 명령문 실행\n",
    "cursor.execute(sql)\n",
    "\n",
    "## 실행 결과 출력\n",
    "response = cursor.fetchall()\n",
    "for data in response:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명령문 실행\n",
    "\n",
    "## 명령문 작성\n",
    "sql = '''\n",
    "commit;\n",
    "'''\n",
    "\n",
    "## 명령문 실행\n",
    "cursor.execute(sql)\n",
    "\n",
    "## 실행 결과 출력\n",
    "response = cursor.fetchall()\n",
    "for data in response:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql 연결 해제\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#             안내사항            #\n",
    "#################################\n",
    "\n",
    "# 1. boto3를 이용하는 방법입니다.\n",
    "# 2. 사용자 계정 세팅은 직접 해주셔야 합니다. 아래 주의사항을 참고해주세요.\n",
    "# 3. 그 외의 사항들은 바로 사용할 수 있게 세팅하였습니다.\n",
    "# 4. 문제 발생시 박종혁에게 연락해주세요.\n",
    "\n",
    "\n",
    "#################################\n",
    "#             주의사항            #\n",
    "#################################\n",
    "\n",
    "# 계정은 각자의 AWS 계정에 해당하는 access_key_id와 aws_secret_accesskey 를 사용해주세요.\n",
    "# 두 가지는 처음 AWS 사용시에 직접 발급받으셨을 겁니다. (강사님께서 절대 까먹지 말라고 하신 것)\n",
    "\n",
    "# 계정을 본 코드에 직접 노출하는 것은 추천하지 않습니다.\n",
    "# AWS CLI 세팅을 통해 미리 access_key_id와 aws_secret_accesskey를 세팅해주신 뒤\n",
    "# 본 코드에는 키가 노출되지 않도록 해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계정 설정 (직접 세팅)\n",
    "# CLI 로 미리 세팅을 해놓기를 바랍니다. 불가능할 경우 아래에 키를 넣어주세요. (하지만 추천하지 않음)\n",
    "\n",
    "# aws_access_key_id = pd.read_csv('키파일.csv').iloc[0].loc['Access key ID']\n",
    "# aws_secret_access_key = pd.read_csv('키파일.csv').iloc[0].loc['Secret access key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 정보 입력\n",
    "\n",
    "resource = ''\n",
    "bucket_name = ''\n",
    "region_name = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boto3.resource() 사용시"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boto3를 이용하는 방법은 두 가지가 있습니다.  \n",
    "1. boto3.resource() 를 사용하는 방법  \n",
    "2. boto3.client() 를 사용하는 방법  \n",
    "\n",
    "먼저, boto3.resource() 메서드를 사용하는 방법을 아래에서 다룹니다.  \n",
    "둘의 차이점은 boto3.client() 설명부에서 다루겠습니다.\n",
    "\n",
    "★★★★★ boto3.client() 방식은 ec2 자동생성 오류때문에 추천하지 않습니다. ★★★★★"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 접속 resource 선언\n",
    "try:\n",
    "    s3 = boto3.resource(resource, aws_access_key_id = aws_access_key_id,\n",
    "                    aws_secret_access_key = aws_secret_access_key,\n",
    "                    region_name = region_name)\n",
    "    # 계정을 직접 입력할 경우\n",
    "except:\n",
    "    s3 = boto3.resource('s3')\n",
    "    # CLI 세팅을 했을 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에 업로드되어있는 파일 확인\n",
    "\n",
    "buckets = s3.Bucket(name = bucket_name)\n",
    "\n",
    "for obj in buckets.objects.all():\n",
    "    print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에 파일 업로드 (방법 1)\n",
    "# s3.meta.client.upload_file('local/file/path', 'bucket_name', 'bucket/file/path')\n",
    "\n",
    "s3.meta.client.upload_file('./file_name.extension', bucket_name, 'file_name.extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에서 파일 다운로드 (방법 1)\n",
    "# s3.meta.client.download_file('bucket_name', 'file_key', 'local/file/path')\n",
    "# file_key = bucket/file/path\n",
    "\n",
    "s3.meta.client.download_file(bucket_name, 'file_name.extension', '/file/path.extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에서 파일 삭제\n",
    "# s3.Object(bucket_name, file_key).delete()\n",
    "\n",
    "s3.Object(bucket_name, 'filename.extension').delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에서 특정 문자가 포함된 파일 삭제\n",
    "\n",
    "buckets = s3.Bucket(name = bucket_name)\n",
    "\n",
    "for i in buckets.objects.all():\n",
    "    if 'test' in i.key:\n",
    "        s3.Object(bucket_name, i.key).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결 종료\n",
    "\n",
    "s3.meta.client.close()\n",
    "buckets.meta.client.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boto3.client() 사용시"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**★★★★★★주의★★★★★★**\n",
    "\n",
    "boto3.client() 방식을 사용할 때에는 주의하시기 바랍니다.  \n",
    "run_instances loop에 빠질 경우 EC2가 자동적으로 생성될 수 있으므로  \n",
    "되도록이면 연결 방식은 boto3.resource 를 사용하시기 바랍니다.  \n",
    "\n",
    "만약 굳이 boto3.client() 방식 연결을 해야할 경우,  \n",
    "가장 하단의 boto3.client의 session configuration 섹션을 참고하여 코딩하시기 바랍니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boto3.resource()와 boto3.client()의 차이\n",
    "\n",
    "boto3의 boto3.resource() 및 boto3.client() 함수는 AWS 서비스와 상호 작용하기 위한 다양한 인터페이스를 제공합니다.\n",
    "\n",
    "boto3.resource() 함수는 AWS 서비스에 대한 상위 수준 객체 지향 인터페이스를 반환합니다. 이 인터페이스는 S3 버킷 또는 EC2 인스턴스와 같은 AWS 리소스를 나타내는 리소스 객체 세트를 제공하고 이러한 리소스와 보다 자연스러운 Python 방식으로 상호 작용할 수 있는 메서드 세트를 노출합니다. 예를 들어 s3.Object(bucket_name, key).put() 또는 s3.Object(bucket_name, key).get()과 같은 메서드를 사용하여 S3 객체에 대한 작업을 수행할 수 있습니다.\n",
    "\n",
    "반면 boto3.client() 함수는 AWS 서비스에 대한 하위 수준 인터페이스를 반환하여 AWS API 주변에 얇은 래퍼를 제공합니다. 이 인터페이스는 AWS API 작업에 직접 해당하는 일련의 메서드를 노출하며 필요한 모든 파라미터를 명시적으로 지정해야 합니다. 예를 들어 s3.get_object(Bucket=bucket_name, Key=key) 또는 s3.put_object(Bucket=bucket_name, Key=key, Body=object_data)와 같은 메서드를 사용하여 S3 객체에 대한 작업을 수행할 수 있습니다.\n",
    "\n",
    "일반적으로 AWS 리소스에 대한 보다 Python적인 객체 지향 인터페이스를 원하는 경우 boto3.resource()를 사용하고, AWS API 작업에 대한 세밀한 제어가 필요한 경우 boto3.client()를 사용해야 합니다.\n",
    "\n",
    "-- chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 클라이언트 선언\n",
    "\n",
    "s3_client = boto3.client('s3', aws_access_key_id = aws_access_key_id,\n",
    "                         aws_secret_access_key = aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에 업로드 되어있는 파일 확인\n",
    "\n",
    "res = s3_client.list_objects_v2(Bucket = bucket_name)\n",
    "\n",
    "for obj in res['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에 파일 업로드 (방법 2)\n",
    "# s3_client.upload_file('/local/file/path', 'bucket_name', 'file_key')\n",
    "# file_key = bucket/file/path\n",
    "\n",
    "s3_client.upload_file('file/path.extension', bucket_name, 'file_name.extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에서 파일 다운로드 (방법 2)\n",
    "# s3_client.download_file('bucket_name', 'file_key', 'local/file/path')\n",
    "# file_key = bucket/file/path\n",
    "\n",
    "s3_client.download_file(bucket_name, 'file_name.extension', 'file/path.extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에서 파일 삭제\n",
    "# s3_client.delete_object(Bucket=bucket_name, Key=object_key)\n",
    "\n",
    "s3_client.delete_object(Bucket = bucket_name, Key = 'file_name.extension')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix 의 개념"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3에는 객체 스토리지 서비스로, 전통적인 directory 개념이 없다.  \n",
    "개체는 버킷으로 구성되고 고유 키(경로)로 식별된다.  \n",
    "\n",
    "대신 고유 키는 전통적인 디렉토리 구조를 모방하고 있어,  \n",
    "계층 구조처럼 슬래시를 포함한 키를 가질 수 있다.\n",
    "\n",
    "prefix는 접두사로, 전통적인 디렉토리 입장으로 보자면 '특정 폴더'로 정의할 수 있을 것이다.  \n",
    "\n",
    "예를 들어  \n",
    "로컬 컴퓨터에 /Users/Desktop/file.txt 라는 파일이 있다고 생각해보자.  \n",
    "file.txt는 Users 디렉토리 안의 Desktop 안에 위치하고 있으며,  \n",
    "따라서 file.txt의 경로는 /Users/Desktop/file.txt로 정의된다.  \n",
    "\n",
    "예시를 이어 들어보면  \n",
    "S3에도 /Users/Desktop/file.txt 라는 파일이 있다고 생각해보자.  \n",
    "전통적 구조와 달리 이 파일은 디렉토리에 담겨있는 게 아니라  \n",
    "\"/Users/Desktop/file.txt\" 이라는 키를 가진 파일 자체로 S3에 저장되어있다.  \n",
    "따라서 디렉토리를 하나씩 들어갈 수는 없지만, 해당 경로로 파일에는 접근할 수 있는 것이다.  \n",
    "\n",
    "여기서 prefix는 \"/Users/Desktop/\"이 될 것이다.  \n",
    "\n",
    "Prefix의 용도는  \n",
    "전통적인 directory 구조에서 \"특정 폴더 안의 파일\"만을 찾는다거나 \"특정 폴더를 삭제\" 하는 등의 역할을  \n",
    "대신 해줄 수 있게 해준다.  \n",
    "\n",
    "이해가 안된다면 어렵게 생각하지 말고, 그냥 \"파일이 위치한 폴더\"로 이해해도 큰 무리는 없을 것 같다.  \n",
    "하지만 이해함.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prefix 는 boto3.client() 방법에서만 사용이 가능하다.  \n",
    "resource 방법으로는 사용이 불가능하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 클라이언트 선언\n",
    "\n",
    "s3_client = boto3.client('s3', aws_access_key_id = aws_access_key_id,\n",
    "                         aws_secret_access_key = aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에 업로드 되어있는 파일 확인\n",
    "\n",
    "res = s3_client.list_objects_v2(Bucket = bucket_name)\n",
    "\n",
    "for obj in res['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버킷에 파일 업로드 (방법 2)\n",
    "\n",
    "prefix = '/test/sqls/'\n",
    "local_file = '/Users/user/Desktop/test.sql'\n",
    "\n",
    "s3_client.upload_file(local_file, bucket_name, prefix + 'test3.sql')\n",
    "s3_client.upload_file(local_file, bucket_name, prefix + 'test4.sql')\n",
    "s3_client.upload_file(local_file, bucket_name, prefix + 'test5.sql')\n",
    "s3_client.upload_file(local_file, bucket_name, prefix + 'test6.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /test/sqls/ 접두사를 가지는 파일 모두 삭제\n",
    "\n",
    "buckets = s3.Bucket(name = bucket_name)\n",
    "\n",
    "for i in buckets.objects.all():\n",
    "    if prefix in i.key:\n",
    "        s3_client.delete_object(Bucket = bucket_name, Key = i.key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Access key 및 RDS ID, PW 숨기기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS를 다룰 때 중요한 것 중 하나는 바로 보안이다.  \n",
    "참고로 나의 경우 EC2 key 보안 관리를 잘 못 했다가.. 큰 손해가 발생했다.  \n",
    "\n",
    "AWS의 Access key를 노출했다가,  \n",
    "(추측컨데) 외부인이 해당 키를 이용해 여러 EC2 인스턴스를 생성, 거의 100% 풀가동을 하여  \n",
    "많은 비용이 발생했다.  \n",
    "앞으로 개발자로 살아간다면, 평생 잊지 말아야 할 큰 말썽이다.  \n",
    "\n",
    "아래에서는 이러한 불상사가 일어나지 않게 AWS 접근 키들을 숨기는 방법을 서술한다.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS 접근 키들을 숨기는 방식은 여러 가지가 있겠지만,  \n",
    "가장 널리, 그리고 안전한 방법으로 쓰이는 것은 바로 \"시스템 환경 변수\"를 사용하는 것이다.  \n",
    "\n",
    "시스템 환경 변수는 해당 로컬에만 값이 저장되고, 언제 어디서든 불러올 수 있다는 게 장점이다.  \n",
    "더불어, 환경변수명을 모를 경우 어떤 정보를 어떻게 불러와야하는지 알 수 없으며,  \n",
    "환경변수명을 알더라도 이를 이용하기 위한 암호 설정, 사용자별 권한 제어 등을 통해 보안을 강화하면 비교적 안전하게 보호할 수 있다.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환경 변수의 보안을 보장하기 위해 몇 가지 모범 사례를 따르는 한 환경 변수를 사용하여 AWS RDS 인스턴스 자격 증명을 저장하는 것이 중요한 정보를 보호하는 안전한 방법이 될 수 있습니다.\n",
    "\n",
    "다음은 따라야 할 몇 가지 모범 사례입니다.\n",
    "\n",
    "안전한 환경 변수 설정: 인증되지 않은 사용자나 프로세스가 액세스할 수 없도록 환경 변수를 안전하게 설정해야 합니다. 예를 들어 암호로 보호된 터미널 세션과 같은 보안 환경에서 환경 변수를 설정하거나 환경 변수를 암호화하는 dotenv와 같은 도구를 사용할 수 있습니다.\n",
    "\n",
    "코드에 환경 변수를 노출하지 마십시오: 실수로 코드나 출력에 환경 변수를 노출하지 않도록 하십시오. 예를 들어 환경 변수의 값을 인쇄하지 말고 로그 파일이나 오류 메시지에 포함하지 마십시오.\n",
    "\n",
    "환경 변수에 대한 액세스 제한: 인증된 사용자 및 프로세스만 환경 변수에 액세스할 수 있는지 확인하십시오. 예를 들어 파일 권한을 설정하거나 암호에 대한 액세스를 관리하는 Key Vault와 같은 도구를 사용하여 환경 변수에 대한 액세스를 제한할 수 있습니다.\n",
    "\n",
    "자격 증명을 정기적으로 교체: 자격 증명이 손상될 위험을 최소화하려면 자격 증명을 정기적으로 교체해야 합니다. 예를 들어 AWS 액세스 키와 보안 액세스 키를 90일마다 교체하고 그에 따라 환경 변수를 업데이트할 수 있습니다.\n",
    "\n",
    "이러한 모범 사례를 따르면 민감한 정보를 보호하기 위해 환경 변수를 안전하게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "외부 파일(예: Excel 파일 또는 .env 파일)에서 AWS RDS 인스턴스 자격 증명을 로드하면 암호를 보다 쉽게 ​​관리하고 실수로 코드에 노출되는 것을 방지할 수 있습니다. 그러나 외부 파일이 안전하게 저장되고 승인된 사용자만 액세스할 수 있는지 확인해야 합니다.\n",
    "\n",
    "다음은 외부 파일의 보안을 유지하는 데 도움이 되는 몇 가지 모범 사례입니다.\n",
    "\n",
    "파일을 안전하게 저장: 권한이 없는 사용자나 프로세스가 액세스할 수 없도록 외부 파일을 안전하게 저장해야 합니다. 예를 들어 파일을 암호화된 드라이브나 암호로 보호된 폴더에 저장할 수 있습니다.\n",
    "\n",
    "파일에 대한 액세스 제한: 승인된 사용자 및 프로세스만 외부 파일에 액세스할 수 있는지 확인하십시오. 예를 들어 파일 권한을 설정하거나 암호에 대한 액세스를 관리하는 Key Vault와 같은 도구를 사용하여 파일에 대한 액세스를 제한할 수 있습니다.\n",
    "\n",
    "파일 암호화: 비밀을 더욱 보호하기 위해 GPG와 같은 도구를 사용하여 외부 파일을 암호화할 수 있습니다. 이렇게 하면 파일이 도난당하거나 손상된 경우에도 비밀에 대한 무단 액세스를 방지할 수 있습니다.\n",
    "\n",
    "자격 증명을 정기적으로 교체: 자격 증명이 손상될 위험을 최소화하려면 자격 증명을 정기적으로 교체해야 합니다. 예를 들어 AWS 액세스 키와 보안 액세스 키를 90일마다 교체하고 이에 따라 외부 파일을 업데이트할 수 있습니다.\n",
    "\n",
    "이러한 모범 사례를 따르면 중요한 정보를 보호하기 위해 외부 파일을 안전하게 사용할 수 있습니다. 그러나 2단계 인증 사용, 의심스러운 활동에 대한 AWS RDS 인스턴스 모니터링, 소프트웨어 최신 상태 유지와 같은 다른 보안 조치도 고려하여 공격으로부터 시스템을 보호해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 환경변수 파일을 만들어준 뒤, key=value 내용을 적는다.\n",
    "# 환경변수 파일은 본 프로젝트의 루트 디렉토리에 저장된다.\n",
    "\n",
    "path = os.getcwd() + '/some.env'\n",
    "with open(path, 'a') as f:\n",
    "    f.write('SOME1=첫번째value입니다.')\n",
    "    f.write('\\nSOME2=두번째value입니다.')\n",
    "    f.write('\\nSOME3=세번째value입니다.')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOME123\n",
      "SOME223\n",
      "SOME323\n"
     ]
    }
   ],
   "source": [
    "# 환경변수 불러오기\n",
    "\n",
    "load_dotenv(dotenv_path='./some.env')\n",
    "\n",
    "print(os.environ['SOME1'])\n",
    "print(os.environ['SOME2'])\n",
    "print(os.environ['SOME3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOME123\n",
      "SOME223\n",
      "SOME323\n"
     ]
    }
   ],
   "source": [
    "# 환경변수 불러오기 : 보통 불러오는 환경변수 명을 노출하지 않는 게 현명하다.\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.environ['SOME1'])\n",
    "print(os.environ['SOME2'])\n",
    "print(os.environ['SOME3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb8359be6a560857f8eb0aaecce6bb12c0bb00fea3cf8b6849d87a5096a4a846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
