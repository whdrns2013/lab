{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94b47e6d-18a2-4915-8f11-275a1e490e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크래핑 대상 및 최종 자료 파일 이름 정의\n",
    "\n",
    "country = 'us'          # 국가 코드\n",
    "app_id = '1163786766'   # 앱스토워 웹페이지에서 확인 가능\n",
    "app_name = 'alarmy'     # 아무거나 입력해도 됨\n",
    "scrap_date = '20230129' # 스크래핑 일자 (달라도 상관 없음)\n",
    "last_page = 10          # 현재 10페이지까지만 지원됨\n",
    "file_name = f'scrap_apple_{app_name}_{country}_{scrap_date}.csv' # 저장할 파일 이름\n",
    "\n",
    "# 국가코드 -- 한국 : kr / 미국 : us ...\n",
    "# 그 외 국가코드는 https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "60445eb1-8555-4e87-9e19-1c7a87921744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크랩 메서드 정의\n",
    "\n",
    "def scrapping_alarmy_apple(page_num, app_id, country):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request\n",
    "    url_start = f'https://itunes.apple.com/{country}/rss/customerreviews/page='\n",
    "    url_end = f'/id={app_id}/sortby=mostrecent/xml?urlDesc=/customerreviews/id={app_id}/sortBy=mostRecent/xml'\n",
    "    html = urllib.request.urlopen(url_start + str(page_num) + url_end)\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    soups = soup.find_all('entry')\n",
    "    \n",
    "    title = []\n",
    "    content = []\n",
    "    rating = []\n",
    "    date = []\n",
    "    version = []\n",
    "    name = []\n",
    "    \n",
    "    for soup in soups:\n",
    "        try:\n",
    "            title.append(soup.find('title').string)\n",
    "        except:\n",
    "            title.append('None')\n",
    "        try:\n",
    "            content.append(soup.find('content', attrs={'type':'text'}).string)\n",
    "        except:\n",
    "            content.append('None')\n",
    "        try:\n",
    "            rating.append(soup.find('im:rating').string)\n",
    "        except:\n",
    "            rating.append('None')\n",
    "        try:\n",
    "            date.append(soup.find('updated').string)\n",
    "        except:\n",
    "            date.append('None')\n",
    "        try:\n",
    "            version.append(soup.find('im:version').string)\n",
    "        except:\n",
    "            version.append('None')\n",
    "        try:\n",
    "            name.append(soup.find('name').string)\n",
    "        except:\n",
    "            name.append('None')\n",
    "    \n",
    "    return title, content, rating, date, version, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4cabb34f-5f44-4271-a108-568b3303f556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 스크랩 실행\n",
    "\n",
    "ls_title = []\n",
    "ls_content = []\n",
    "ls_rating = []\n",
    "ls_date = []\n",
    "ls_version = []\n",
    "ls_name = []\n",
    "\n",
    "for i in range(1, last_page + 1):\n",
    "    title, content, rating, date, version, name = scrapping_alarmy_apple(i, app_id, country)\n",
    "    \n",
    "    ls_title.append(title)\n",
    "    ls_content.append(content)\n",
    "    ls_rating.append(rating)\n",
    "    ls_date.append(date)\n",
    "    ls_version.append(version)\n",
    "    ls_name.append(name)\n",
    "\n",
    "title = [ x.string for comps in ls_title for x in comps ]\n",
    "content = [ x.string for comps in ls_content for x in comps ]\n",
    "rating = [ x.string for comps in ls_rating for x in comps ]\n",
    "date = [ x.string for comps in ls_date for x in comps ]\n",
    "version = [ x.string for comps in ls_version for x in comps ]\n",
    "name = [ x.string for comps in ls_name for x in comps ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b17feb87-cca4-415a-b621-b2b0d5804104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# csv 파일로 저장\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([title, content, rating, date, version, name]).T\n",
    "df.columns = ['title', 'content', 'rating', 'date', 'version', 'author']\n",
    "df.to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
